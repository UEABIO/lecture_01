<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Intro to linear models</title>
    <meta charset="utf-8" />
    <meta name="author" content="Philip Leftwich" />
    <meta name="date" content="2023-02-05" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/my-theme.css" type="text/css" />
    <link rel="stylesheet" href="css/my-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">






class: title-slide, left, top

# Intro to linear models

## Term 2

### Philip Leftwich

&lt;br&gt;



&lt;span style='color:white;'&gt;Slides released under&lt;/span&gt; [CC-BY 2.0](https://creativecommons.org/licenses/by/2.0/)&amp;nbsp;&amp;nbsp;<svg aria-hidden="true" role="img" viewBox="0 0 496 512" style="height:1em;width:0.97em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:white;overflow:visible;position:relative;"><path d="M245.83 214.87l-33.22 17.28c-9.43-19.58-25.24-19.93-27.46-19.93-22.13 0-33.22 14.61-33.22 43.84 0 23.57 9.21 43.84 33.22 43.84 14.47 0 24.65-7.09 30.57-21.26l30.55 15.5c-6.17 11.51-25.69 38.98-65.1 38.98-22.6 0-73.96-10.32-73.96-77.05 0-58.69 43-77.06 72.63-77.06 30.72-.01 52.7 11.95 65.99 35.86zm143.05 0l-32.78 17.28c-9.5-19.77-25.72-19.93-27.9-19.93-22.14 0-33.22 14.61-33.22 43.84 0 23.55 9.23 43.84 33.22 43.84 14.45 0 24.65-7.09 30.54-21.26l31 15.5c-2.1 3.75-21.39 38.98-65.09 38.98-22.69 0-73.96-9.87-73.96-77.05 0-58.67 42.97-77.06 72.63-77.06 30.71-.01 52.58 11.95 65.56 35.86zM247.56 8.05C104.74 8.05 0 123.11 0 256.05c0 138.49 113.6 248 247.56 248 129.93 0 248.44-100.87 248.44-248 0-137.87-106.62-248-248.44-248zm.87 450.81c-112.54 0-203.7-93.04-203.7-202.81 0-105.42 85.43-203.27 203.72-203.27 112.53 0 202.82 89.46 202.82 203.26-.01 121.69-99.68 202.82-202.84 202.82z"/></svg><svg aria-hidden="true" role="img" viewBox="0 0 496 512" style="height:1em;width:0.97em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:white;overflow:visible;position:relative;"><path d="M314.9 194.4v101.4h-28.3v120.5h-77.1V295.9h-28.3V194.4c0-4.4 1.6-8.2 4.6-11.3 3.1-3.1 6.9-4.7 11.3-4.7H299c4.1 0 7.8 1.6 11.1 4.7 3.1 3.2 4.8 6.9 4.8 11.3zm-101.5-63.7c0-23.3 11.5-35 34.5-35s34.5 11.7 34.5 35c0 23-11.5 34.5-34.5 34.5s-34.5-11.5-34.5-34.5zM247.6 8C389.4 8 496 118.1 496 256c0 147.1-118.5 248-248.4 248C113.6 504 0 394.5 0 256 0 123.1 104.7 8 247.6 8zm.8 44.7C130.2 52.7 44.7 150.6 44.7 256c0 109.8 91.2 202.8 203.7 202.8 103.2 0 202.8-81.1 202.8-202.8.1-113.8-90.2-203.3-202.8-203.3z"/></svg> ]   

&lt;div style = "position: absolute;top: 0px;right: 0px;"&gt;&lt;img src="images/logo.png" alt="The hex logo for plumbertableau package" width="500"&gt;&lt;/img&gt;&lt;/div&gt;

---

layout: true

&lt;div class="my-footer"&gt;&lt;span&gt;Philip Leftwich - 5023Y Courses Slido.com #2496824&lt;/span&gt;&lt;/div&gt;


---
class: center, middle

## What is a linear model?

---

A linear model a statistical tool used to **model relationships** between variables and **make predictions** based on those relationships.


It describes the relationship between a dependent and (one or more) independent variables

    - The independent variable could be categorical or continuous

--

    - The dependent variable is always continuous
 
--

&lt;img src="images/diff_reg_simple.png" title="R model summary provides, the formula of the regression, the estimate of the intercept and standard error, estimated differences and uncertainity for each slope, the degrees of freedom for the whole model, F value and R squared" alt="R model summary provides, the formula of the regression, the estimate of the intercept and standard error, estimated differences and uncertainity for each slope, the degrees of freedom for the whole model, F value and R squared" width="90%" /&gt;

---

*For example*: 

If we have data on the height and weight of a group of people, we could use a linear model to model the relationship between height (the independent variable) and weight (the dependent variable). The resulting linear equation would allow us to make predictions about the weight of a person based on their height.

--

Or

--

If we have data on the height from two groups of maize plants (selfed and crossed), we could use a linear model to model the relationship between height (the independent variable) and group (the dependent variable). The resulting linear equation would allow us to make predictions about the height of a plant based on inbreeding or crossing.

--

&lt;img src="images/diff_reg_simple.png" title="R model summary provides, the formula of the regression, the estimate of the intercept and standard error, estimated differences and uncertainity for each slope, the degrees of freedom for the whole model, F value and R squared" alt="R model summary provides, the formula of the regression, the estimate of the intercept and standard error, estimated differences and uncertainity for each slope, the degrees of freedom for the whole model, F value and R squared" width="80%" /&gt;



---

# The `lm()` function in R

The linear model function in R is a convenient tool for fitting linear models and performing statistical analyses.

```
lm(y ~ x, data = data)

```

Where: 

--

- `lm()` : is the linear model function in R

--

- `y`: is the name of the dependent variable

--

- `x`: is the name of the indepdent variable

--

- `data`: is the name of the dataframe/tibble that contains both variables


---

# Calculations by hand

In the last lecture and workshop we worked out how to:

- Calculate means &amp; mean differences

--

- Calculate standard error

--

- Calculate 95% confidence intervals

--

- Understand the assumptions


---

# Mean difference

Mean differences are the differences between the means of two groups

--

`\(Mean~difference = \overline x_1 - \overline x_2\)`

---

# Standard Error of the difference

The uncertainty of the difference between two means

where `\(s\)` = standard deviation

--

.pull-left[ 

### Equal variance not assumed
`\(SED = \sqrt{s_1^2\over n_1}+{s_2^2\over n_2}\)`

]

--

.pull-right[


### Equal variance assumed

`\(s_{pooled}^2 = {{(n_1-1)s_1^2+(n_2-1)s_2^2} \over n_1 + n_2-2}\)`


`\(SED_{pooled} = s_{pooled}^2 {\sqrt{1\over n_1} + {1\over n_2}}\)`

]

---

# Confidence intervals

A 95% confidence interval for the mean difference is a range of values that is expected to contain the true mean difference with a probability of 95%.

--

If the same study were repeated many times and a 95% confidence interval were calculated each time, we would expect the true mean difference to fall within the interval 95% of the time.

--

&lt;img src="images/CI-experiments.png" title=" Confidence Intervals" alt=" Confidence Intervals" width="60%" /&gt;

---

# Confidence intervals

The 95% confidence interval for a mean difference is calculated based on the standard error of the difference and the critical value from a probability distribution.


`\({95\%~CI} = {\overline x \pm 1.96*SE}\)`

--

So far we have used the *z* distribution where the critical value for the 95%CI is always 1.96

--

Later we will work with the *t* distribution, where the critical value changes with sample size


---

# Assumptions

- Samples are independent

--

- We have a normal distribution

--

- The sample size is big enough for the Central Limit Theorem

--

- At least 30 (per group)

---

# Linear models in R

- Faster

--

- More accurate

--

- Detailed Output

--

- Reproducible

---

# Model summary

```
model &lt;- lm(height ~ type, data = darwin)

summary(model)
```
--

&lt;img src="images/model_summary.png" title="R model summary provides, the formula of the regression, the estimate of the intercept and standard error, estimated differences and uncertainity for each slope, the degrees of freedom for the whole model, F value and R squared" alt="R model summary provides, the formula of the regression, the estimate of the intercept and standard error, estimated differences and uncertainity for each slope, the degrees of freedom for the whole model, F value and R squared" width="70%" /&gt;



---

# Model summary

&lt;img src="images/model_summary.png" title="R model summary provides, the formula of the regression, the estimate of the intercept and standard error, estimated differences and uncertainity for each slope, the degrees of freedom for the whole model, F value and R squared" alt="R model summary provides, the formula of the regression, the estimate of the intercept and standard error, estimated differences and uncertainity for each slope, the degrees of freedom for the whole model, F value and R squared" width="60%" /&gt;


Coefficients: Estimates produced by the model. For example the Intercept estimates the height of the crossed plants. The typeSelf line represents the average decrease in height

---

# Model summary


&lt;img src="images/model_summary.png" title="R model summary provides, the formula of the regression, the estimate of the intercept and standard error, estimated differences and uncertainity for each slope, the degrees of freedom for the whole model, F value and R squared" alt="R model summary provides, the formula of the regression, the estimate of the intercept and standard error, estimated differences and uncertainity for each slope, the degrees of freedom for the whole model, F value and R squared" width="60%" /&gt;

Standard error: A measure of the variability or error. The difference betweent the observed values and those predicted by the model


---


# Assumptions of a linear model

- Linearity: The relationship between the dependent variable and the independent variable(s) should be linear

--

- Independence: The observations should be independent of each other, meaning that one observation should not have an effect on another observation

--

- Homoscedasticity: The variance of the error term should be constant for all values of the independent variable(s). 


---

# Homoscedasticity

.pull-left[

&lt;img src="images/homoscedasticity.png" width="50%" /&gt;

]

.pull-right[

&lt;img src="images/heteroscedasticity.png" width="110%" /&gt;

]


---


# Assumptions of a linear model


- Linearity: The relationship between the dependent variable and the independent variable(s) should be linear


- Independence: The observations should be independent of each other, meaning that one observation should not have an effect on another observation


- Homoscedasticity: The variance of the error term should be constant for all values of the independent variable(s). 

--

- Normality: The *error* should be normally distributed. The residuals should be normally distributed around the estimated mean


---


# Final thoughts

- The linear model is a fast, accurate way of comparing mean differences.

--

- It is a fundamental part of statitics and machine learning

--

- We can build complexity to tackle different analysis problems

--

- It is important to apply the method responsibly and considering assumptions.

---

class: center, middle, inverse

# Next time: T-distributions

### Reading 

 Chapter 9: Discovering Statistics using R/SPSS - Andy Field

 Chapter 6: The New Statistics - Andy Hector

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "dracula",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
