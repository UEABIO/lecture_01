---
title: "ANOVA"
subtitle: "ANalysis Of VAriance"
author: "Philip Leftwich"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    css: ["default", "css/my-theme.css", "css/my-fonts.css"]
    seal: false
    lib_dir: libs
    nature:
      ratio: '16:9'
      highlightStyle: dracula
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE,
        eval = TRUE, warning = FALSE, message = FALSE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE, fig.retina = 3, fig.asp = 0.8, fig.width = 7, out.width = "120%")

library(tidyverse)
library(here)
library(gt)
library(gtExtras)
library(rstatix)
library(palmerpenguins)
library(DiagrammeR)


```



class: title-slide, left, top

# `r rmarkdown::metadata$title`

## `r rmarkdown::metadata$subtitle`

### `r rmarkdown::metadata$author`

<br>



<span style='color:white;'>Slides released under</span> [CC-BY 2.0](https://creativecommons.org/licenses/by/2.0/)&nbsp;&nbsp;`r fontawesome::fa("creative-commons", "white")``r fontawesome::fa("creative-commons-by", "white")` ]

<span style='color:white;'>Slido #47032854</span>

<div style = "position: absolute;top: 0px;right: 0px;"><img src="images/logo.png" alt="The hex logo for plumbertableau package" width="500"></img></div>

---

layout: true

<div class="my-footer"><span>Philip Leftwich - 5023Y Courses Slido.com #47032854</span></div>



---

## z and t distributions

```{r, echo = F, out.width = "70%"}
x <- seq(-5, 5, by = 0.1)
y1 <- dt(x, df = 1)
y2 <- dt(x, df = 3)
y3 <- dt(x, df = 8)
y4 <- dt(x, df = 30)
y5 <- dnorm(x)
plot(x, y1, type = "l", col = "red", 
     xlab = "x", 
     ylab = "Density", 
     main = "T Distributions and Normal Distribution",
     ylim = c(0,0.4),
     xlim = c(-5, 5))
lines(x, y2, col = "blue")
lines(x, y3, col = "green")
lines(x, y4, col = "purple")
lines(x, y5, col = "black", lty = 2)
legend("topright", legend = c("df = 1", "df = 3", "df = 8", "df = 30", "Normal"), col = c("red", "blue", "green", "purple", "black"), lty = c(1, 1, 1, 1, 2))
```


---
## Model summary

In this example of a simple linear model, we run the equivalent to a Student's t-test.

```{r, echo = FALSE, out.width="60%", fig.alt = "R model summary provides, the formula of the regression, the estimate of the intercept and standard error, estimated differences and uncertainity for each slope, the degrees of freedom for the whole model, F value and R squared"}
knitr::include_graphics("images/model_summary.png")
```

**Q. What happens when we have more than two groups in our predictor variable? Why can't we just do more t-tests?**

---

class: center

# ANalysis Of VAriance (ANOVA)

ANOVAs use information about variances, but the main goal of analysis is comparison of MEANS (don’t let the name mix you up - more on this later).

--

**ANOVA is an omnibus test** – it tests for significant differences between any means in the study

--

**ANOVA is just a special case of the linear model**

---

## ANOVA Hypotheses:

**Null Hypothesis (H0):** All means are equal (in other words, all groups are from populations with the same mean)

--

**Alternative Hypothesis (HA):** At least two group means are NOT equal (that means that just two could be different, or they could ALL be different)


---

## Example 


.pull-left[
We have collected data for soil uranium concentrations at three locations on Los Alamos National Lab property: Site A, Site B, and Site C. The data structure is shown below: 
]


.pull-right[
```{r, echo = FALSE, out.width="120%", fig.alt = "A tidy dataframe illustrating one continuous dependent variable and and one factor predictor variable (with three levels)"}
knitr::include_graphics("images/three_level.png")
```
]

--

A one-way ANOVA can be used to assess whether there is a statistically significant difference in uranium concentration in soil at three locations

---

## One-way ANOVA (single factor)

What does this one-way/single-factor refer to? 

There is a **single factor** (*variable*), with at least 3 **levels**, where we are trying to compare means across the different levels of that factor.

ANOVA does this *indirectly* by looking at total *between* and *within* group variances as a ratio (F).

```{r, echo = FALSE, out.width="70%", fig.alt = ""}
knitr::include_graphics("images/understand-ANOVA.png")
```

---

.left-code[

$$
SSE = \underset{i=1}{n \atop{\sum}}(y_i - \hat{y_i})^2
$$



$$
SSR = \underset{i=1}{n \atop{\sum}}(\hat{y_i} - \overline{y})^2
$$


$$
SST = \underset{i=1}{n \atop{\sum}}(y_i - \overline{y})^2
$$

where:

$y_i$ = Observed value

$\hat{y_i}$ = Value estimated by model

$\overline{y}$ = The Grand Mean



]

.right-plot[
```{r, echo = FALSE, out.width="100%", fig.alt = "A tidy dataframe illustrating one continuous dependent variable and and one factor predictor variable (with three levels)"}
knitr::include_graphics("images/SSR-SST.png")
```

]

--

$SSE + SSR = SST$

---

## What does an ANOVA actually do?

.pull-left[

.huge[

$$
F = {SSR / (k-1)\over SSE / (N-k)} = {MSR\over MSE}
$$
]


$k$ = Total number of groups

$N$ = **numerator** degrees of freedom = Total number of observations across all groups

$N-k$ = **denominator** degrees of freedom

$MSR$ = Mean Squares Regression

$MSE$ = Mean Squares Error

This is a **ratio** of the between group variance and the the within group variance. 

]

.pull-right[


```{r, echo = FALSE, out.width="120%", fig.alt = ""}
knitr::include_graphics("images/one-way-ANOVA.png")
```

]

---

## F distribution

.left-code[

The F-value or ratio of variances, over their respective degrees of freedom will have an F-distribution. 

This F distribution is used when we want to compare within and between group variances.

The curve of the distribution depends on the degrees of freedom, and it is always positively skewed

]

.right-plot[

```{r, echo = F, out.width = "110%"}
x <- seq(0.001, 5, by = 0.001)
y1 <- df(x, df1 = 1, df2 = 1)
y2 <- df(x, df1 = 2, df2 = 1)
y3 <- df(x, df1 = 5, df2 = 2)
y4 <- df(x, df1 = 10, df2 = 1)
y5 <- df(x, df1 = 100, df2 = 100)

plot(x, y1, type = "l", col = "red", lwd = 2,
     xlab = "x", 
     ylab = "Density", 
     main = "F Distributions",
     ylim = c(0,3),
     xlim = c(0.001, 4))
lines(x, y2, col = "blue", lwd = 2)
lines(x, y3, col = "green", lwd = 2)
lines(x, y4, col = "purple", lwd = 2)
lines(x, y5, col = "black", lwd = 2)
legend("topright", legend = c("df1 = 1, df2 = 1", "df1 = 2, df2 = 1", "df1 = 5, df2 = 2", "df1 = 10, df2 = 1", "df1 = 100, df2 = 100"), col = c("red", "blue", "green", "purple", "black"), lty = c(1, 1, 1, 1, 1))
```

]

---

The **higher** the *F*-value the greater the *signal-to-noise* ratio. 

--

For a given value of **numerator** and **denominator** degrees of freedom we can look up the probability of observing this ratio under a null hypothesis of identical variances.

--

If F value is high enough then we might have enough evidence to conclude that samples are likely drawn from populations with *different* means.

--

```{r, echo = FALSE, out.width="60%", fig.alt = ""}
knitr::include_graphics("images/F-test-sig.jpg")
```

---
class: center, middle, inverse

#Ask a question about: ANOVA

---

## Example

.left-code[
```{r}
bulbs <- read_csv(here::here("data", "bulbs.csv"))
bulbs %>% 
  head() %>% 
  gt()

```
]

.right-plot[
.tiny[

```{r}
bulb_lsmodel0 <- lm(lifetime_hours ~ bulb_type, data = bulbs)

summary(bulb_lsmodel0)

anova(bulb_lsmodel0)

```

]]

---

class: center, middle, inverse

# Post-hoc vs. Planned contrasts


---

## Correcting for multiple comparisons

The *F*-ratio tells us only whether the model fitted to the data (SSR) accounts for more variance than other factors (SSE). 

So if the *F*-ratio is large enough to be statistically significant, then we only know that *one or more* differences between means are statistically significant.

Further testing is needed! 

--

### Planned contrasts

- You focused on a *few* scientifically sensible comparisons, rather than every possible comparison

- You chose these *as part of the experimental design* before collecting data

- Could structure linear model to reflect this?

---

### Post hoc

- Typically unplanned comparisons, conducted only after a significant ANOVA result

- All combinations checked

- Needs correcting for inflated Type 1 error

--

| Method     | Equation | Notes|
| ----------- | ----------- |----------- |
| Bonferroni/Dunn-Sidak    | $p = {\alpha \over k}$      | Correct critical p for the number of independent tests
| Holm's    | $p_{1} < \alpha/(k–1+1) = \alpha/k$      | we start with the smallest p-value (i = 1) and determine whether there is a significant result (i.e. p1 < α/(k–1+1) = α/k. If so we move on to the second test. We continue in this manner until we get a non-significant result
| Tukey HSD  | $t_{crit} = q * \sqrt{MSE \over N}$  | Essential a t-test, correcting for multiple comparison, q-values can be looked up for test df and number of treatments

---

## Post hoc testing

.tiny[

```{r, echo = F}
library(emmeans)
```

```{r, out.width = "90%"}


means <- emmeans(bulb_lsmodel0, 
                 specs = pairwise ~ bulb_type)

confint(means)

```

]

---
class: middle, center, inverse

# Next time: Multivariate models


### Reading 

 Chapters ANOVA: Discovering Statistics using R/SPSS - Andy Field

 Chapter ANOVA: The New Statistics - Andy Hector




